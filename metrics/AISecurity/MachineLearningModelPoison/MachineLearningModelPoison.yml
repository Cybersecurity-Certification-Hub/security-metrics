# Metadata
id: MachineLearningModelPoison
description: This rule assesses whether a [MachineLearningModel] can defenses against data poisoning attacks.
version: 1.0
comments: Poisoning attacks aim to corrupt a model during training by injecting malicious samples. Models should have ability to face such situation.
---
# Configuration data
configuration:
  poisonDefenseEnabled:
    operator: ==
    targetValue: true
  metricType:
    operator: in 
    targetValue: ["SLEEPAgent"]
  poisonLevel:
    operator: <=
    targetValue: 0.5
